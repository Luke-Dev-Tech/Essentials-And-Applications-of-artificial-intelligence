{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luke-Dev-Tech/Essentials-And-Applications-of-artificial-intelligence/blob/main/EAI_(Recycling).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1] Kaggle Json"
      ],
      "metadata": {
        "id": "RqIF0f1vgu3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "kaggle_json = \"/content/drive/My Drive/UWE Projects/EAI/kaggle.json\""
      ],
      "metadata": {
        "id": "2qFttMh5guDd",
        "outputId": "30627309-3623-4532-faa5-193b84c6546d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "shutil.copyfile(kaggle_json, os.path.expanduser('~/.kaggle/kaggle.json'))\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QdfVC1q2hVFN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Modular Section"
      ],
      "metadata": {
        "id": "4JP6rB-sfZXK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01371af1"
      },
      "source": [
        "!mkdir -p modular"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2.1] kaggle_data.py"
      ],
      "metadata": {
        "id": "O2p1vRvG6HSv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noqev_zCelvX"
      },
      "outputs": [],
      "source": [
        "%%writefile modular/kaggle_data.py\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "def kaggleDataImport(dataset_name: str):\n",
        "    \"\"\"\n",
        "    dataset_name example:\n",
        "    'feyzazkefe/trashnet'\n",
        "    \"\"\"\n",
        "\n",
        "    data_path = Path(\"data\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    zip_name = dataset_name.split(\"/\")[-1] + \".zip\"\n",
        "    zip_path = data_path / zip_name\n",
        "\n",
        "    # ---------------- Download ----------------\n",
        "    if not zip_path.exists():\n",
        "        print(f\"[Info] Downloading {dataset_name} ...\")\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"kaggle\",\n",
        "                \"datasets\",\n",
        "                \"download\",\n",
        "                \"-d\",\n",
        "                dataset_name,\n",
        "                \"-p\",\n",
        "                str(data_path)\n",
        "            ],\n",
        "            check=True\n",
        "        )\n",
        "    else:\n",
        "        print(\"[Success] Zip already exists\")\n",
        "\n",
        "    # ---------------- Unzip ----------------\n",
        "    print(\"[Info] Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(data_path)\n",
        "\n",
        "    # ---------------- Detect extracted folder ----------------\n",
        "    extracted_items = [\n",
        "        p for p in data_path.iterdir()\n",
        "        if p.is_dir() and p.name != \"__MACOSX\"\n",
        "    ]\n",
        "\n",
        "    if len(extracted_items) == 1:\n",
        "        dataset_dir = extracted_items[0]\n",
        "    else:\n",
        "        # Multiple folders â†’ choose most recent\n",
        "        dataset_dir = max(extracted_items, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "    print(\"[Success] Dataset ready at:\", dataset_dir)\n",
        "\n",
        "    # ---------------- Cleanup ----------------\n",
        "    os.remove(zip_path)\n",
        "\n",
        "    return dataset_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2.2] data_setup.py"
      ],
      "metadata": {
        "id": "WsejebNbqRuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile modular/data_setup.py\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    data_dir: str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    num_workers: int = NUM_WORKERS\n",
        "):\n",
        "    train_data = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
        "    test_data = datasets.ImageFolder(root=data_dir, transform=test_transform)\n",
        "\n",
        "    class_names = train_data.classes\n",
        "    indices = list(range(len(train_data)))\n",
        "\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        indices,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        shuffle=True,\n",
        "        stratify=train_data.targets\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(train_data, train_idx)\n",
        "    test_dataset = Subset(test_data, test_idx)\n",
        "\n",
        "    print(f\"[INFO] Total images: {len(train_data)}\")\n",
        "    print(f\"[INFO] Training images: {len(train_dataset)}\")\n",
        "    print(f\"[INFO] Testing images: {len(test_dataset)}\")\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return (train_dataloader, test_dataloader, class_names, train_dataset, test_dataset, train_idx, test_idx)"
      ],
      "metadata": {
        "id": "eqerwIe5kOSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2.3] engine.py"
      ],
      "metadata": {
        "id": "I9Lm7ygWkZFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile modular/engine.py\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Main Method (1): Train Step\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fun: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Do the forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Calculate and Accumulate the loss\n",
        "    loss = loss_fun(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Optimizer Zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # opitmizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate and accumulate accuracy metric acorss all batches\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "# Main Method (2): Test Step\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fun: torch.nn.Module,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              device: torch.device\n",
        "              ):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fun(y_pred, y)\n",
        "      test_loss += loss.item()\n",
        "      test_acc += (torch.argmax(torch.softmax(y_pred, dim=1), dim=1) == y).sum().item()/len(y_pred)\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "# Main Method (3): Initiate\n",
        "def initiate_train_test(model: torch.nn.Module,\n",
        "           train_dataloader: torch.utils.data.DataLoader,\n",
        "           test_dataloader: torch.utils.data.DataLoader,\n",
        "           optimizer: torch.optim.Optimizer,\n",
        "           loss_fun: torch.nn.Module,\n",
        "           epochs: int,\n",
        "           device: torch.device) -> Dict[str, List]:\n",
        "  \"\"\"\n",
        "  :\n",
        "  :return: Retrun a dictionary containing Training loss, training acc, test loss and test acc.\n",
        "  This initiate training and testing processes by using the data loaded by dataloader.\n",
        "\n",
        "  \"\"\"\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []\n",
        "             }\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fun=loss_fun,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fun=loss_fun,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch: {epoch+1} | \"\n",
        "        f\"train_loss: {train_loss:.4f} | \"\n",
        "        f\"train_acc: {train_acc:.4f} | \"\n",
        "        f\"test_loss: {test_loss:.4f} | \"\n",
        "        f\"test_acc: {test_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  return results\n",
        "\n"
      ],
      "metadata": {
        "id": "meckiLcJkXk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2.4] utlis.py"
      ],
      "metadata": {
        "id": "kd9lDKn8kbw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile modular/utils.py\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name:str):\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(), f=model_save_path)\n"
      ],
      "metadata": {
        "id": "VlXqaJUBkd3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2.5] pred_and_plot_img.py"
      ],
      "metadata": {
        "id": "Ri3GNG2Gkiuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile modular/pred_and_plot_img.py\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def pred_and_plot_img(\n",
        "    model: torch.nn.Module,\n",
        "    image_path: str,\n",
        "    class_name: List[str],\n",
        "    image_size: Tuple[int, int] = (224, 224),\n",
        "    transform: torchvision.transforms = None,\n",
        "    device: torch.device = device\n",
        "):\n",
        "    # Load image\n",
        "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Use provided transform or default VGG-Face transform\n",
        "    if transform is None:\n",
        "        transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(image_size),\n",
        "            torchvision.transforms.Grayscale(num_output_channels=3),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "              mean=[0.485, 0.456, 0.406],\n",
        "              std=[0.229, 0.224, 0.225]\n",
        "          )\n",
        "        ])\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "        logits = model(img_tensor)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred_idx = probs.argmax(dim=1).item()\n",
        "        pred_prob = probs.max().item()\n",
        "\n",
        "    actual_label = Path(image_path).parent.name\n",
        "    pred_label = class_name[pred_idx]\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(img_pil)\n",
        "    plt.title(\n",
        "        f\"Actual: {actual_label} | Pred: {pred_label} | Prob: {pred_prob:.3f}\"\n",
        "    )\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "WXs1nqBYkkj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [3] Pipeline"
      ],
      "metadata": {
        "id": "Iox7Um1-kpQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from modular import kaggle_data, data_setup, engine, utils, pred_and_plot_img\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "\n",
        "\n",
        "#====================Device Setup=============================\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#=============================================================\n",
        "# Kaggle Data Import\n",
        "kaggle_data.kaggleDataImport('feyzazkefe/trashnet')\n",
        "#=================Attribute Section===========================\n",
        "# NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "# HIDDEN_UNITS = 10\n",
        "# LEARNING_RATE = 0.0005\n",
        "data_dir = 'data/dataset-resized'\n",
        "#=============================================================\n",
        "# Data_setup\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((260, 260)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((260, 260)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "train_dataloader, test_dataloader, class_names , train_dataset, test_dataset, train_index, test_index = data_setup.create_dataloaders(\n",
        "  data_dir=data_dir,\n",
        "  train_transform=train_transform,\n",
        "  test_transform=test_transform,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  test_size=0.2  # 80/20 split\n",
        ")\n",
        "#=============================================================\n",
        "# Engine\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "#=======================EfficientNet B2============================#\n",
        "#=========================={PHASE 1}===============================#\n",
        "# PHASE (1): Backbone\n",
        "# EPOCH - 5\n",
        "# LR - 0.001\n",
        "# Backbone\n",
        "# New optimizer [Mandatory]\n",
        "# Weight decay [ADDed]\n",
        "#\n",
        "#=============================================================\n",
        "weigths = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b2(weights=weigths).to(device)\n",
        "#=============================================================\n",
        "num_classes = len(class_names)\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1408, out_features=num_classes, bias=True)\n",
        ").to(device)\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "#=============================================================\n",
        "#===============Loss function and Optimizer===================\n",
        "loss_fun = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "#=============================================================\n",
        "print(\"======== PHASE 1: Training ==========\")\n",
        "start_time = timer()\n",
        "engine.initiate_train_test(\n",
        "  model=model,\n",
        "  train_dataloader=train_dataloader,\n",
        "  test_dataloader=test_dataloader,\n",
        "  loss_fun=loss_fun,\n",
        "  optimizer=optimizer,\n",
        "  epochs=10,\n",
        "  device=device\n",
        ")\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "print(\"=======================================\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4HJAK01DEuGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=========================={PHASE 2}===============================#\n",
        "# PHASE (2): fine Tuning\n",
        "# EPOCH - 3\n",
        "# LR - 0.0001\n",
        "# New optimizer [Mandatory]\n",
        "# Weight decay [Not added]\n",
        "# 26/02/2026\n",
        "#=============================================================\n",
        "# UnFreeze 1 Layer\n",
        "for param in model.features[-1:].parameters():\n",
        "    param.requires_grad = True\n",
        "#=============================================================\n",
        "#===============Loss function and Optimizer===================\n",
        "loss_fun = torch.nn.CrossEntropyLoss()\n",
        "optimizer_phase2 = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=0.0001\n",
        ")#=============================================================\n",
        "print(\"======== PHASE 2: Training ==========\")\n",
        "start_time = timer()\n",
        "engine.initiate_train_test(\n",
        "  model=model,\n",
        "  train_dataloader=train_dataloader,\n",
        "  test_dataloader=test_dataloader,\n",
        "  loss_fun=loss_fun,\n",
        "  optimizer=optimizer_phase2,\n",
        "  epochs=5,\n",
        "  device=device\n",
        ")\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "_-R15BAFp843"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=================Utils for saving models=====================\n",
        "utils.save_model(\n",
        "      model=model,\n",
        "      target_dir='models',\n",
        "      model_name=f'Recycle_Model_.pth'\n",
        ")\n",
        "#============================================================="
      ],
      "metadata": {
        "id": "DzdYRRm9ppMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [4] Random 3 IMG Testing"
      ],
      "metadata": {
        "id": "2X4ilSHBm-yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image # Import Image for PIL operations\n",
        "from pathlib import Path # Import Path to handle paths\n",
        "\n",
        "def pred_and_plot_img(model: torch.nn.Module,\n",
        "                     image_path: str,\n",
        "                     class_names: List[str],\n",
        "                     image_size: Tuple[int, int] = (224, 224),\n",
        "                     transform: torchvision.transforms = None,\n",
        "                     device: torch.device = \"cpu\"):\n",
        "\n",
        "    # 1. Load and prepare image\n",
        "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    if transform is not None:\n",
        "        img_transform = transform\n",
        "    else:\n",
        "        img_transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(image_size),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                             std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    # 2. Prediction logic\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Move transformed image to device\n",
        "        transformed_img = img_transform(img_pil).unsqueeze(dim=0).to(device)\n",
        "        logits = model(transformed_img)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred_label_idx = torch.argmax(probs, dim=1).item()\n",
        "        pred_class = class_names[pred_label_idx]\n",
        "\n",
        "    # 3. Extract actual label safely\n",
        "    # This assumes your directory is: data_dir/class_name/image.jpg\n",
        "    actual_label = Path(image_path).parent.name\n",
        "\n",
        "    # 4. Plotting\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(img_pil)\n",
        "\n",
        "    # Color code the title: Green for correct, Red for wrong\n",
        "    title_color = \"g\" if pred_class == actual_label else \"r\"\n",
        "\n",
        "    plt.title(f\"Actual: {actual_label} | Pred: {pred_class}\\nProb: {probs.max():.3f}\",\n",
        "              color=title_color)\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "TUNiqfWXcY8u"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Instead of globbing the whole folder, use the indices from your split\n",
        "# Assuming 'test_dataset' is what was returned by your create_dataloaders function\n",
        "num_images_to_plot = 15\n",
        "for _ in range(num_images_to_plot):\n",
        "    # Get a random index from the test_dataset\n",
        "    random_idx = random.randint(0, len(test_index)-1)\n",
        "\n",
        "    # Get the image path from the underlying ImageFolder samples list\n",
        "    # test_dataset.indices maps the subset index back to the original index\n",
        "    original_idx = test_dataset.indices[random_idx]\n",
        "    image_path, _ = test_dataset.dataset.samples[original_idx]\n",
        "\n",
        "    pred_and_plot_img(\n",
        "        model=model,\n",
        "        image_path=image_path,\n",
        "        class_names=class_names,\n",
        "        transform=test_transform,\n",
        "        device=device\n",
        "    )"
      ],
      "metadata": {
        "id": "Iu0jLtwdTsa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [5] Custom IMG TESTing"
      ],
      "metadata": {
        "id": "OF7u0t7KnE32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "def custom_img_testing(link: str):\n",
        "  custom_img_path = Path(f'data/custom_img_{round(random.random(), 3)}.jpg')\n",
        "\n",
        "  if not custom_img_path.is_file():\n",
        "    print(f\"Downloading custom image ... \")\n",
        "    with open(custom_img_path, \"wb\") as f:\n",
        "      request = requests.get(link)\n",
        "      f.write(request.content)\n",
        "  else:\n",
        "    print(f\"{custom_img_path} already exists\")\n",
        "\n",
        "  return custom_img_path\n",
        "\n",
        "\n",
        "pred_and_plot_img(\n",
        "    model=model,\n",
        "    image_path=custom_img_testing(link=\"https://previews.123rf.com/images/picsfive/picsfive2001/picsfive200100370/138798094-close-up-of-a-paper-ball-trash-on-white-background.jpg\"),\n",
        "    class_names=class_names,\n",
        "    transform=test_transform,\n",
        "    device=device\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "WEtLh-mKcbsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn scikit-learn"
      ],
      "metadata": {
        "id": "G4UprEpKsFXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "wzNVPq4XsJbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "3_yzV5p6sJuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cmap=\"Blues\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ZFU1ZIPsJwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))"
      ],
      "metadata": {
        "id": "3qqYfLM3sJzd",
        "outputId": "e40a53f7-d10d-4f14-cfdc-3fa45e614b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.92      0.89      0.91        81\n",
            "       glass       0.87      0.81      0.84       100\n",
            "       metal       0.78      0.90      0.84        82\n",
            "       paper       0.83      0.89      0.86       119\n",
            "     plastic       0.80      0.77      0.79        97\n",
            "       trash       0.83      0.56      0.67        27\n",
            "\n",
            "    accuracy                           0.84       506\n",
            "   macro avg       0.84      0.80      0.82       506\n",
            "weighted avg       0.84      0.84      0.83       506\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f\"\\nOverall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall: {recall:.4f}\")\n",
        "print(f\"Overall F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "3TkUdhvZs_I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "report = classification_report(all_labels, all_preds,\n",
        "                               target_names=class_names,\n",
        "                               output_dict=True)\n",
        "\n",
        "df = pd.DataFrame(report).transpose()\n",
        "\n",
        "metrics = df.loc[class_names][[\"precision\", \"recall\", \"f1-score\"]]\n",
        "\n",
        "metrics.plot(kind=\"bar\")\n",
        "plt.title(\"Precision, Recall, F1-score per Class\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kR0tGYr-tLvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KN_5dHY7tObB"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}